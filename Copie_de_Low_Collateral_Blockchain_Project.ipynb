{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raph3103/hw4atam/blob/main/Copie_de_Low_Collateral_Blockchain_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nv0qzgkl8fa"
      },
      "source": [
        "# Low Collateral Blockchain Project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZXKVH5nl8fd",
        "scrolled": false,
        "outputId": "40855fd0-8967-4164-eac5-dd1cbb9b0cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "DsJ-C0L3l8fe",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULM8nHMul8ff"
      },
      "source": [
        "Get the stat file: We will start by obtaining the stat file, which contains relevant data for our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "YCq-Dwiel8ff"
      },
      "outputs": [],
      "source": [
        "data = pd.read_pickle('/content/HistoryPoolBorrowersStats.pkl')\n",
        "\n",
        "df = pd.DataFrame.from_dict(data,orient='index')\n",
        "\n",
        "chemin_fichier_csv = 'newStats.csv'\n",
        "\n",
        "df.to_csv(chemin_fichier_csv, index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5CnrkV_l8fg"
      },
      "source": [
        "Add columns and modify the existing file: We will enhance the stat file by adding new columns and modifying existing ones to better suit our analysis requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "lAwVZbZXl8fg"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv('newStats.csv')\n",
        "\n",
        "\n",
        "columns_to_remove = ['datesSupplyCollateral', 'datesLoan','datesReimbursement','datesWithdrawCollateral','timeUTCFirstAnyTransactionAccount','borrowerAgeInYears','totalLoans','NumLoans','MeanLoans','totalTimeloans','MeanTimeLoans','totalSupplyCollateral','NumSupplyCollateral','MeanSupplyCollateral','totalReimbursements','NumReimbursements','MeanReimbursements','NumTransactions']  # Specify the names of the columns to remove\n",
        "df = df.drop(columns=columns_to_remove)\n",
        "\n",
        "\n",
        "\n",
        "df.to_csv('newStats.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C21x-gy0xWs5"
      },
      "source": [
        "This part transfor the dict from date keys to tomestamps keys and also add a new value named ratio for each timestamsp if size debt = 0 then collateralDebtRatio = infinity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "AGSg8wuuGV--"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "df = pd.read_csv('newStats.csv')\n",
        "\n",
        "\n",
        "\n",
        "def date_to_timestamp(date_str):\n",
        "    dt_object = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
        "    timestamp = int(time.mktime(dt_object.timetuple()))\n",
        "    return timestamp\n",
        "\n",
        "\n",
        "for i, cell in enumerate(df['Calendar']):\n",
        "    if isinstance(cell, str):\n",
        "        cell = cell.replace(\"'\", '\"')\n",
        "        calendar_dict = json.loads(cell)\n",
        "        new_calendar_dict = {}\n",
        "        for date_str, day_dict in calendar_dict.items():\n",
        "            timestamp = date_to_timestamp(date_str)\n",
        "            if day_dict['sizeDebtUSD'] != 0:\n",
        "                ratio = day_dict['sizeCollateralUSD'] / day_dict['sizeDebtUSD']\n",
        "            else:\n",
        "                ratio = float('inf')\n",
        "            day_dict['collateralDebtRatio'] = ratio\n",
        "\n",
        "            new_calendar_dict[timestamp] = day_dict\n",
        "        df.at[i, 'Calendar'] = json.dumps(new_calendar_dict)\n",
        "    else:\n",
        "        continue\n",
        "df.to_csv('newStats.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUeNPet2ysVm"
      },
      "source": [
        "adding most frequent time in the day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "8sDYb_wSODZd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def timestamp_to_category(timestamp):\n",
        "    dt_object = datetime.fromtimestamp(int(float(timestamp)))\n",
        "    hour = dt_object.hour\n",
        "    if 6 <= hour < 12:\n",
        "        return \"Morning\"\n",
        "    elif 12 <= hour < 18:\n",
        "        return \"Afternoon\"\n",
        "    elif 18 <= hour < 24:\n",
        "        return \"Evening\"\n",
        "    else:\n",
        "        return \"Night\"\n",
        "\n",
        "def most_frequent_category(lst):\n",
        "    return max(set(lst), key=lst.count) if lst else None\n",
        "\n",
        "df = pd.read_csv('newStats.csv')\n",
        "timestamp_cols = ['timeStampsSupplyCollateral', 'timeStampsLoans', 'timeStampsReimbursement', 'timeStampsWithdrawCollateral', 'timeStampFirstAnyTransactionAccount']\n",
        "df['MostFrequentTransactionTimeOfDay'] = \"\"\n",
        "for i, row in df.iterrows():\n",
        "    categories = []\n",
        "    for col in timestamp_cols:\n",
        "        if pd.isnull(row[col]):\n",
        "            continue\n",
        "        timestamps = str(row[col]).split()\n",
        "        for timestamp in timestamps:\n",
        "            categories.append(timestamp_to_category(timestamp))\n",
        "    df.at[i, 'MostFrequentTransactionTimeOfDay'] = most_frequent_category(categories)\n",
        "df.to_csv('newStats.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G98wEsVFy9Fp"
      },
      "source": [
        "count the number of days with high ratio(1 but we can change the value if needed) for each user, using the new value in the calendar colomn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "5HOszi7OX36u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "threshold = 2.2\n",
        "\n",
        "def count_days_with_high_ratio(calendar_str):\n",
        "    if not isinstance(calendar_str, str):\n",
        "        return None\n",
        "    calendar = json.loads(calendar_str)\n",
        "\n",
        "    count = 0\n",
        "    for day, attributes in calendar.items():\n",
        "        if 'collateralDebtRatio' in attributes and attributes['collateralDebtRatio'] > threshold:\n",
        "            count += 1\n",
        "    return count\n",
        "df['DaysWithHighRatio'] = df['Calendar'].apply(count_days_with_high_ratio)\n",
        "df.to_csv('newStats.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-yeA_AA4Pv"
      },
      "source": [
        "if the user paid x percent in the last y month the val is true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "6izVyBdscZzp"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "\n",
        "x_percent=0.1\n",
        "\n",
        "y_month=9\n",
        "def loan_repaid_x_percent_in_last_y_months(calendar):\n",
        "    six_months_ago = 1668297600 - y_month*30*24*60*60\n",
        "    if isinstance(calendar, str):\n",
        "        calendar_dict = json.loads(calendar)\n",
        "    else:\n",
        "        return False\n",
        "    total_loan = 0\n",
        "    total_repayment = 0\n",
        "    for timestamp, day_dict in calendar_dict.items():\n",
        "        timestamp = int(timestamp)\n",
        "        if six_months_ago <= timestamp <= 1668297600:\n",
        "            total_loan += day_dict['sizeDebtUSD']\n",
        "            total_repayment += day_dict['amountPaymentsOnDay']\n",
        "    if total_loan == 0:\n",
        "        return False\n",
        "    repayment_percentage = total_repayment / total_loan\n",
        "    if repayment_percentage >= x_percent:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "df['LoanRepaidxPercentInLastyMonths'] = df['Calendar'].apply(loan_repaid_x_percent_in_last_y_months)\n",
        "df.to_csv('newStats.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDxL3wRIl8fg"
      },
      "source": [
        "Create a function to evaluate user behavior: We will develop a function that determines whether a user is classified as good or bad based on their activities on our platform. This function will help us assess user behavior and identify potential risks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "ipRb7__Hl8fg"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "today = datetime.now()\n",
        "\n",
        "six_months_ago = today - timedelta(days=15*30)\n",
        "timestamp_today = int(today.timestamp())\n",
        "timestamp_six_months_ago = int(six_months_ago.timestamp())\n",
        "\n",
        "\n",
        "def evaluate_user_behavior(row):\n",
        "    conditions_met = 0\n",
        "\n",
        "\n",
        "    if row['DaysWithHighRatio'] > 60:\n",
        "        conditions_met += 2\n",
        "        if row['LoanRepaidxPercentInLastyMonths']:\n",
        "          conditions_met += 4\n",
        "    if row['timeStampFirstAnyTransactionAccount'] < timestamp_six_months_ago :\n",
        "        conditions_met += 1\n",
        "\n",
        "    if conditions_met==5 or conditions_met == 6 or conditions_met==7 or conditions_met == 3:\n",
        "        return 'Good'\n",
        "    elif conditions_met ==0 :\n",
        "        return 'Bad'\n",
        "    else:\n",
        "        return 'Unknown'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDRE0T7Sl8fh"
      },
      "source": [
        "Run the function for all rows: We will iterate over each row of the stat file and apply the user evaluation function to determine the classification for each user.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "LYNHcE2Kl8fh"
      },
      "outputs": [],
      "source": [
        "df['user_class'] = df.apply(evaluate_user_behavior, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "290gzDGil8fh"
      },
      "source": [
        "Add the new column to the CSV: After evaluating all the users, we will add the newly generated classification column to the CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "fM234biwl8fi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = df.drop(columns='Calendar')\n",
        "df.to_csv('updated_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF7eGzRVl8fi"
      },
      "source": [
        "Run a machine learning model: With the updated CSV file, we will utilize a machine learning model to gain insights and predictions based on the user behavior data.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def user_class_distribution(data: pd.DataFrame):\n",
        "    label_counts = data[\"user_class\"].value_counts().reset_index()\n",
        "    label_counts.columns = ['Rating', 'Count']\n",
        "    label_counts['Rating'] = label_counts['Rating'].map({0: 'Bad', 1: 'Good', 2: 'Unknown'})\n",
        "    fig = px.bar(\n",
        "        label_counts,\n",
        "        x='Rating',\n",
        "        y='Count',\n",
        "        title='Label Distribution',\n",
        "        labels={'Rating': 'user_class', 'Count': 'Count'},\n",
        "        color='Rating',  # Apply colors to each category\n",
        "        color_discrete_map={'Bad': 'blue', 'Good': 'green', 'Unknown': 'orange',},  # Specify colors\n",
        "    )\n",
        "\n",
        "    # Customize layout and appearance\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"user_class\",\n",
        "        yaxis_title=\"Count\",\n",
        "        legend_title=\"Label Category\",\n",
        "        font=dict(size=12),\n",
        "    )\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "80hgvFAJXaHK"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# data = pd.read_csv('updated_data.csv')\n",
        "# # Création d'une nouvelle colonne binaire pour indiquer si le collatéral a été retiré ou non\n",
        "# data['collateralWithdrawn'] = data['timeStampsWithdrawCollateral'].notnull().astype(int)\n",
        "\n",
        "# # Supprimer la colonne originale 'timeStampsWithdrawCollateral' car nous avons maintenant une représentation binaire\n",
        "# data = data.drop(columns=['timeStampsWithdrawCollateral'])\n",
        "\n",
        "# # Vérifier les modifications\n",
        "# data[['collateralWithdrawn']].head()\n",
        "# # Supprimer l'enregistrement avec des valeurs manquantes\n",
        "# data_cleaned = data.dropna()\n",
        "\n",
        "# # Vérifier si les valeurs manquantes ont été supprimées\n",
        "# remaining_missing_values = data_cleaned.isnull().sum().sum()\n",
        "# remaining_missing_values, data_cleaned.shape\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.pipeline import Pipeline\n",
        "\n",
        "# # Identification des colonnes catégorielles et numériques\n",
        "# categorical_cols = data_cleaned.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "# numerical_cols = data_cleaned.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# # Supprimer la colonne 'Unnamed: 0' qui semble être un identifiant et la variable cible 'user_class'\n",
        "# categorical_cols.remove('Unnamed: 0')\n",
        "# categorical_cols.remove('user_class')\n",
        "\n",
        "# # Préparation des transformateurs pour les colonnes numériques et catégorielles\n",
        "# numerical_transformer = StandardScaler()\n",
        "# categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# # Préparation du préprocesseur pour appliquer ces transformations\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('num', numerical_transformer, numerical_cols),\n",
        "#         ('cat', categorical_transformer, categorical_cols)\n",
        "#     ])\n",
        "\n",
        "# # Séparation des données en features et target\n",
        "# X = data_cleaned.drop(columns=['Unnamed: 0', 'user_class'])\n",
        "# y = data_cleaned['user_class']\n",
        "\n",
        "# # Division des données en ensembles d'entraînement et de test\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Application du préprocesseur\n",
        "# X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "# X_test_transformed = preprocessor.transform(X_test)\n",
        "\n",
        "# X_train_transformed.shape, X_test_transformed.shape\n",
        "# # Supprimer uniquement la colonne 'LoanRepaidxPercentInLastyMonths', ainsi que 'Unnamed: 0' (username) et 'user_class'\n",
        "# X_reduced_final = data_cleaned.drop(columns=['Unnamed: 0', 'user_class', 'LoanRepaidxPercentInLastyMonths'])\n",
        "\n",
        "# # Mise à jour des listes des colonnes numériques et catégorielles\n",
        "# numerical_cols_reduced_final = X_reduced_final.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "# categorical_cols_reduced_final = X_reduced_final.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "\n",
        "# # Mise à jour du préprocesseur pour appliquer ces transformations\n",
        "# preprocessor_reduced_final = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('num', numerical_transformer, numerical_cols_reduced_final),\n",
        "#         ('cat', categorical_transformer, categorical_cols_reduced_final)\n",
        "#     ])\n",
        "\n",
        "# # Application du préprocesseur\n",
        "# X_train_reduced_final, X_test_reduced_final, y_train_reduced_final, y_test_reduced_final = train_test_split(X_reduced_final, y, test_size=0.2, random_state=42)\n",
        "# X_train_transformed_reduced_final = preprocessor_reduced_final.fit_transform(X_train_reduced_final)\n",
        "# X_test_transformed_reduced_final = preprocessor_reduced_final.transform(X_test_reduced_final)\n",
        "\n",
        "# # Réentraînement du modèle de Forêt Aléatoire\n",
        "# random_forest_model_reduced_final = RandomForestClassifier(random_state=42)\n",
        "# random_forest_model_reduced_final.fit(X_train_transformed_reduced_final, y_train_reduced_final)\n",
        "\n",
        "# # Prédiction sur l'ensemble de test réduit\n",
        "# y_pred_reduced_final = random_forest_model_reduced_final.predict(X_test_transformed_reduced_final)\n",
        "\n",
        "# # Évaluation du modèle réduit\n",
        "# classification_report_result_reduced_final = classification_report(y_test_reduced_final, y_pred_reduced_final)\n",
        "# confusion_matrix_result_reduced_final = confusion_matrix(y_test_reduced_final, y_pred_reduced_final)\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Obtenir l'importance des caractéristiques du modèle de forêt aléatoire\n",
        "# feature_importances = random_forest_model_reduced_final.feature_importances_\n",
        "\n",
        "# # Récupérer les noms des caractéristiques après la transformation\n",
        "# feature_names_transformed = preprocessor_reduced_final.get_feature_names_out()\n",
        "\n",
        "# # Trier les caractéristiques par importance\n",
        "# sorted_indices = np.argsort(feature_importances)[::-1]\n",
        "# sorted_feature_importances = feature_importances[sorted_indices]\n",
        "# sorted_feature_names = feature_names_transformed[sorted_indices]\n",
        "\n",
        "# # Afficher les 10 caractéristiques les plus importantes\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.title(\"Top 10 most important features\")\n",
        "# plt.bar(range(10), sorted_feature_importances[:10], align='center')\n",
        "# plt.xticks(range(10), sorted_feature_names[:10], rotation=45, ha='right')\n",
        "# plt.xlabel('Features')\n",
        "# plt.ylabel('Importance')\n",
        "# plt.show()\n",
        "\n",
        "# # Sélectionner la caractéristique la plus importante\n",
        "# top_feature = sorted_feature_names[0]\n",
        "\n",
        "# # Décoder le nom de la caractéristique pour obtenir le nom original dans le jeu de données\n",
        "# original_feature_name = top_feature.split(\"__\")[1] if \"__\" in top_feature else top_feature\n",
        "\n",
        "# # Afficher la distribution de cette caractéristique pour chaque classe\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# for class_name in data_cleaned['user_class'].unique():\n",
        "#     subset = data_cleaned[data_cleaned['user_class'] == class_name]\n",
        "#     plt.hist(subset[original_feature_name], bins=20, alpha=0.5, label=class_name)\n",
        "\n",
        "# plt.title(f\"Distribution of the feature by classe\")\n",
        "# plt.xlabel(original_feature_name)\n",
        "# plt.ylabel('Number of observations')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # Création d'un DataFrame pour comparer les prédictions avec les valeurs réelles\n",
        "# comparison_df = pd.DataFrame({'Actual': y_test_reduced_final, 'Predicted': y_pred_reduced_final})\n",
        "\n",
        "# # Trouver un exemple d'une bonne classification\n",
        "# correct_classification = comparison_df[comparison_df['Actual'] == comparison_df['Predicted']].sample(1)\n",
        "# correct_index = correct_classification.index[0]\n",
        "\n",
        "# # Trouver un exemple d'une mauvaise classification\n",
        "# incorrect_classification = comparison_df[comparison_df['Actual'] != comparison_df['Predicted']].sample(1)\n",
        "# incorrect_index = incorrect_classification.index[0]\n",
        "\n",
        "# # Extraire les détails de ces deux exemples du jeu de données original\n",
        "# correct_example = data_cleaned.loc[correct_index]\n",
        "# incorrect_example = data_cleaned.loc[incorrect_index]\n",
        "\n",
        "# correct_example, incorrect_example\n",
        "\n",
        "# # Histogramme de la distribution des scores pour chaque classe\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# for class_name in data_cleaned['user_class'].unique():\n",
        "#     subset = data_cleaned[data_cleaned['user_class'] == class_name]\n",
        "#     plt.hist(subset['DaysWithHighRatio'], bins=20, alpha=0.5, label=class_name)\n",
        "\n",
        "# plt.title(\"Distribution of 'DaysWithHighRatio' by Classe\")\n",
        "# plt.xlabel('DaysWithHighRatio')\n",
        "# plt.ylabel('Nombre of Observations')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # Matrice de confusion pour le modèle\n",
        "# from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# ConfusionMatrixDisplay.from_predictions(y_test_reduced_final, y_pred_reduced_final)\n",
        "# plt.title('Confusion matrix for the model')\n",
        "# plt.show()\n",
        "\n",
        "# # Graphique de l'importance des caractéristiques\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.title(\"Feature Importance (Top 10)\")\n",
        "# plt.bar(range(10), sorted_feature_importances[:10], align='center')\n",
        "# plt.xticks(range(10), sorted_feature_names[:10], rotation=45, ha='right')\n",
        "# plt.xlabel('Features')\n",
        "# plt.ylabel('Importance')\n",
        "# plt.show()\n",
        "# #print(df.describe())\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "#df = df.drop(columns=['Calendar'])\n",
        "for col in ['timeStampsSupplyCollateral', 'timeStampsLoans', 'timeStampsReimbursement', 'timeStampsWithdrawCollateral','maximumDebt', 'atTimeMaximumDebtCollateralProvided']:\n",
        "    df= df.drop(columns=col)\n",
        "\n",
        "rows_with_nan = df[df.isna().any(axis=1)]\n",
        "\n",
        "df.dropna()\n",
        "df['LoanRepaidxPercentInLastyMonths'] = df['LoanRepaidxPercentInLastyMonths'].astype(int)\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['MostFrequentTransactionTimeOfDay'] = le.fit_transform(df['MostFrequentTransactionTimeOfDay'])\n",
        "df['user_class'] = le.fit_transform(df['user_class'])\n",
        "#print(df.describe())\n",
        "scaler = StandardScaler()\n",
        "num_cols = ['sizeLoansUSD', 'sizeCollateralUSD', 'sizeReimbursementsUSD', 'numLoansUser', 'ratioCollateralToLoans', 'averageOfDailyCollateralToDebt', 'numTransactionsUser', 'DaysWithHighRatio']\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "for cols in ['DaysWithHighRatio','timeStampFirstAnyTransactionAccount','LoanRepaidxPercentInLastyMonths']:\n",
        "  df = df.drop(columns=cols)\n",
        "X = df.drop('user_class', axis=1)\n",
        "y = df['user_class']\n",
        "\n",
        "#print(X.head())\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "X_train = X_train.dropna()\n",
        "y_train = y_train[X_train.index]"
      ],
      "metadata": {
        "id": "GBRc27IZg-vl"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qAs04ERmfV3"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# # Entraînement du modèle KNN\n",
        "# knn_model = KNeighborsClassifier(n_neighbors=5)  # Utilisation de 5 voisins pour commencer\n",
        "# knn_model.fit(X_train_transformed_reduced_final, y_train_reduced_final)\n",
        "\n",
        "# # Prédiction sur l'ensemble de test\n",
        "# y_pred_knn = knn_model.predict(X_test_transformed_reduced_final)\n",
        "\n",
        "# # Évaluation du modèle KNN\n",
        "# classification_report_knn = classification_report(y_test_reduced_final, y_pred_knn)\n",
        "# confusion_matrix_knn = confusion_matrix(y_test_reduced_final, y_pred_knn)\n",
        "\n",
        "# classification_report_knn, confusion_matrix_knn\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# # Tester différentes valeurs pour 'n_neighbors'\n",
        "# neighbor_values = [3, 5, 7, 10, 15]\n",
        "# cross_val_scores = []\n",
        "\n",
        "# for k in neighbor_values:\n",
        "#     knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "#     scores = cross_val_score(knn_model, X_train_transformed_reduced_final, y_train_reduced_final, cv=5)\n",
        "#     cross_val_scores.append(scores.mean())\n",
        "\n",
        "# # Afficher les résultats\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(neighbor_values, cross_val_scores, marker='o')\n",
        "# plt.title('Model Performance of KNN as a Function of the Number of Neighbors')\n",
        "# plt.xlabel('Number of neighbors (n_neighbors)')\n",
        "# plt.ylabel('Average accuracy (Cross-Validation)')\n",
        "# plt.show()\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "print('Printing informations')\n",
        "print( 'ypred:', (y_pred))\n",
        "#print( 'y_train:', y_train)\n",
        "#print( 'X_test:', X_test)\n",
        "# Convertir les prédictions en DataFrame pandas\n",
        "predictions_df = pd.DataFrame(y_pred, columns=['Prediction'])\n",
        "information_df = pd.DataFrame(X_test,columns=['X_test'])\n",
        "combined_df = pd.concat([information_df, predictions_df], axis=1)\n",
        "# Exporter le DataFrame en fichier CSV\n",
        "combined_df.to_csv('mes_predictions.csv', index=False)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)\n",
        "df__ = pd.DataFrame(X_test)\n",
        "df__.to_csv('mon_fichier.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPVu3_0kaXwB",
        "outputId": "16fbda30-b8c5-4fd1-e4b0-608e29c883c4"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing informations\n",
            "ypred: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "Accuracy: 0.8717948717948718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nRgWkbgRjwIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [3],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'p': [1, 2],\n",
        "}\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "print(f\"Meilleurs paramètres : {best_params}\")\n",
        "print(f'Accuracy avec meilleurs paramètres: {accuracy}')\n",
        "print('Classification Report avec meilleurs paramètres:\\n', report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA9ZJ48Ua3o7",
        "outputId": "75197de5-571b-4380-be98-0bbba3067c2a"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meilleurs paramètres : {'algorithm': 'auto', 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
            "Accuracy avec meilleurs paramètres: 0.8717948717948718\n",
            "Classification Report avec meilleurs paramètres:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.89      0.97      0.93        35\n",
            "\n",
            "    accuracy                           0.87        39\n",
            "   macro avg       0.30      0.32      0.31        39\n",
            "weighted avg       0.80      0.87      0.84        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "DBC7ipi8l8fi",
        "outputId": "d0decd72-cea1-4ed8-ffd7-e4111588a954",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.92      0.97      0.94        35\n",
            "\n",
            "    accuracy                           0.90        39\n",
            "   macro avg       0.64      0.66      0.65        39\n",
            "weighted avg       0.85      0.90      0.87        39\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "rfc = RandomForestClassifier( n_estimators=100, random_state=42)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TRX8y-Bl8fi"
      },
      "source": [
        "Analyze performance: Finally, we will analyze the performance of our machine learning model and evaluate its effectiveness in predicting user behavior accurately."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "\n",
        "print(f\"Meilleurs paramètres : {best_params}\")\n",
        "print(f'Accuracy avec meilleurs paramètres: {accuracy}')\n",
        "print('Classification Report avec meilleurs paramètres:\\n', report)"
      ],
      "metadata": {
        "id": "KkB06FvWfu0Z",
        "outputId": "e2bc3fd2-5d9b-40b2-a977-648f19c3ed7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-200-e8ce1d6bab07>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             trees = [\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             trees = [\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# max_features = 'auto' would cause warnings in every call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Tree.fit(..)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseDecisionTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max_features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:\\n', report)"
      ],
      "metadata": {
        "id": "NFSDb0libGx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "}\n",
        "\n",
        "logistic_regression = LogisticRegression(max_iter=1000)\n",
        "\n",
        "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "\n",
        "print(f\"Meilleurs paramètres : {best_params}\")\n",
        "print(f'Accuracy avec meilleurs paramètres: {accuracy}')\n",
        "print('Classification Report avec meilleurs paramètres:\\n', report)"
      ],
      "metadata": {
        "id": "uysmxx-GivD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7Zl9QNL8iuvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model = SVC(kernel='linear', C=1.0, decision_function_shape='ovr')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:\\n', report)"
      ],
      "metadata": {
        "id": "AESzW8H-bZQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "svm = SVC()\n",
        "\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "print(f\"Meilleurs paramètres : {best_params}\")\n",
        "print(f'Accuracy avec meilleurs paramètres: {accuracy}')\n",
        "print('Classification Report avec meilleurs paramètres:\\n', report)"
      ],
      "metadata": {
        "id": "Y8Xfvxomj5dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "model = XGBClassifier(objective='multi:softmax', num_class=3, seed=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:\\n', report)\n"
      ],
      "metadata": {
        "id": "aNIoGKCzcSyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "}\n",
        "\n",
        "xgb = XGBClassifier(objective='multi:softmax', num_class=3, seed=42)\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "print(f\"Meilleurs paramètres : {best_params}\")\n",
        "print(f'Accuracy avec meilleurs paramètres: {accuracy}')\n",
        "print('Classification Report avec meilleurs paramètres:\\n', report)"
      ],
      "metadata": {
        "id": "nq6zVfkVgGvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', p=2)\n",
        "rf_model = RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=2, min_samples_split=5, n_estimators=100)\n",
        "logistic_model = LogisticRegression(C=0.001, penalty='l2')\n",
        "svm_model = SVC(C=0.1, degree=2, kernel='linear')\n",
        "xgb_model = XGBClassifier(colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=1)\n",
        "\n",
        "models = [('knn', knn_model), ('random_forest', rf_model), ('logistic_regression', logistic_model),\n",
        "          ('svm', svm_model), ('xgboost', xgb_model)]\n",
        "accuracy_scores = []\n",
        "classification_reports = []\n",
        "confusion_matrices = []\n",
        "for model_name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    accuracy_scores.append((model_name, accuracy))\n",
        "    report = classification_report(y_test, predictions, output_dict=True)\n",
        "    classification_reports.append((model_name, report))\n",
        "    conf_matrix = confusion_matrix(y_test, predictions)\n",
        "    confusion_matrices.append((model_name, conf_matrix))\n",
        "for model_name, accuracy in accuracy_scores:\n",
        "    print(f'{model_name} Accuracy: {accuracy}')\n",
        "plt.figure(figsize=(10, 6))\n",
        "classes = [\n",
        "    \"sizeLoansUSD\",\n",
        "    \"sizeCollateralUSD\",\n",
        "    \"sizeReimbursementsUSD\",\n",
        "    \"numLoansUser\",\n",
        "    \"numReimbursementsUser\",\n",
        "    \"ratioCollateralToLoans\",\n",
        "    \"averageOfDailyCollateralToDebt\",\n",
        "    \"numTransactionsUser\",\n",
        "    \"timeStampFirstAnyTransactionAccount\",\n",
        "    \"numLiquidations\",\n",
        "    \"timeStampsLiquidations\",\n",
        "    \"datesLiquidation\",\n",
        "    \"hashLiquidations\",\n",
        "    \"liquidators\",\n",
        "    \"amountLiquidated\",\n",
        "    \"NumLiqudiations\",\n",
        "    \"MostFrequentTransactionTimeOfDay\",\n",
        "    \"DaysWithHighRatio\",\n",
        "    \"LoanRepaidxPercentInLastyMonths\",\n",
        "    \"user_class\"\n",
        "]\n",
        "for model_name, conf_matrix in confusion_matrices:\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes, label=model_name)\n",
        "plt.title('Matrices de Confusion Comparatives')\n",
        "plt.xlabel('Prédictions')\n",
        "plt.ylabel('Vraies étiquettes')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for model_name, report in classification_reports:\n",
        "    print(f'\\n{model_name} Classification Report:\\n', report)"
      ],
      "metadata": {
        "id": "n-67fQwpbDu6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}